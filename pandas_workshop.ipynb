{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pandas_workshop.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT3xMk0aTkwo"
      },
      "source": [
        "# Cool Star Lab Pandas Workshop\n",
        "\n",
        "**Summary**\n",
        "\n",
        "In this tutorial, we're going to explore some of the functionality of Pandas, which is a useful spreadsheet program that allows us to manipulate large sets of data. \n",
        "\n",
        "**Authors**\n",
        "\n",
        "Adam Burgasser\n",
        "\n",
        "**Learning Goals**\n",
        "\n",
        "* Learn how to read in spreadsheets of information into Pandas dataframes\n",
        "* Select rows and columns from these spreadsheets\n",
        "* Change elements in our tables\n",
        "* Create new columns by combining other columns\n",
        "* Obtain quantitative summaries and visualize data\n",
        "* Combine two tables by stacking & merging\n",
        "* Save databases to csv, xlsx, and latex files, and dictionary structures\n",
        "\n",
        "**Keywords**\n",
        "\n",
        "databases, Pandas\n",
        "\n",
        "**Companion Content & Resources** \n",
        "\n",
        "* Pandas documentation: https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_user-5Fguide_index.html-23user-2Dguide&d=DwIGAg&c=-35OiAkTchMrZOngvJPOeA&r=mrAiCY0TeV419Ak3rBjpNvgiyObFA_PAPlLMGcaX54A&m=SzQ4m99FotmuIWDN7LjY3UZc3sRvARoFNfDbkhA32x8&s=WSZRxyulLhPzE6fEYwHFf80FbHKx4jCmCUyJI5_a-IA&e=  - the 10 minutes to pandas is a good intro\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dVShmR7UA_u"
      },
      "source": [
        "# First load up the relavant packages - we only need two!\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfBIzhuob8JV"
      },
      "source": [
        "# Part 1: reading in catalog data and reviewing their contents\n",
        "\n",
        "We're going to make use of a few datasets that are associated with the SPLAT database:\n",
        "\n",
        "* a source catalog\n",
        "* a spectral catalog\n",
        "* a photometry catalog\n",
        "\n",
        "By design, these are truncated to 1500 sources and don't necessary include all the same objects in each table.\n",
        "\n",
        "We're going to use the `read_csv` command to read in csv (comma-separated variables) files from a github repository into Pandas dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHLoYgGkVsWZ"
      },
      "source": [
        "# read in the three catalogs in \"Dataframes\"\n",
        "# Note: you need to be online to do this\n",
        "df_sources = pd.read_csv('https://urldefense.proofpoint.com/v2/url?u=https-3A__raw.githubusercontent.com_aburgasser_splat-5Ftutorials_master_datasets_source-5Fdata.csv-27-2Cdelimiter-3D-27-2C-27-29-255Cn&d=DwIGAg&c=-35OiAkTchMrZOngvJPOeA&r=mrAiCY0TeV419Ak3rBjpNvgiyObFA_PAPlLMGcaX54A&m=SzQ4m99FotmuIWDN7LjY3UZc3sRvARoFNfDbkhA32x8&s=Ot8ZwgNV9A3BsMM3ZG2QUGtML5Q78N4Ur4wuW1XAILM&e= ",
        "df_spectra = pd.read_csv('https://urldefense.proofpoint.com/v2/url?u=https-3A__raw.githubusercontent.com_aburgasser_splat-5Ftutorials_master_datasets_spectral-5Fdata.csv-27-2Cdelimiter-3D-27-2C-27-29-255Cn&d=DwIGAg&c=-35OiAkTchMrZOngvJPOeA&r=mrAiCY0TeV419Ak3rBjpNvgiyObFA_PAPlLMGcaX54A&m=SzQ4m99FotmuIWDN7LjY3UZc3sRvARoFNfDbkhA32x8&s=we_-Ai9c4F0zO2YWkW7ONrBdj_6e-CNyYq2i23M-xFQ&e= ",
        "df_photometry = pd.read_csv('https://urldefense.proofpoint.com/v2/url?u=https-3A__raw.githubusercontent.com_aburgasser_splat-5Ftutorials_master_datasets_photometry-5Fdata.csv-27-2Cdelimiter-3D-27&d=DwIGAg&c=-35OiAkTchMrZOngvJPOeA&r=mrAiCY0TeV419Ak3rBjpNvgiyObFA_PAPlLMGcaX54A&m=SzQ4m99FotmuIWDN7LjY3UZc3sRvARoFNfDbkhA32x8&s=yIijKfYVi--Q8frXg77Sa8pOJQMDQkBgu1fuWaXaers&e= ,')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3mkZYHrZdsA"
      },
      "source": [
        "# take a look at what's in here by just typing the name of the variable\n",
        "df_photometry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvr3LPCagA8B"
      },
      "source": [
        "# what is the type of this table?\n",
        "type(df_sources)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLvXSLphb6Wg"
      },
      "source": [
        "# look at the first several lines of the catalog\n",
        "df_sources.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFb2C27fdlsQ"
      },
      "source": [
        "# look at the last several lines of the catalog\n",
        "df_spectra.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDRNLfrzd4WG"
      },
      "source": [
        "# list the columns\n",
        "df_photometry.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0aeSZuBdn_g"
      },
      "source": [
        "# how big is our table?\n",
        "# number of rows\n",
        "print(len(df_spectra))\n",
        "# number of columns\n",
        "print(len(df_spectra.columns))\n",
        "# total number of elements\n",
        "print(np.size(df_spectra))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewEweHgjeWE-"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "Re-run the commands above for the other two catalogs. What is different between them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDSUwly6efUm"
      },
      "source": [
        "# Part 2: Accessing elements in our table\n",
        "\n",
        "In this section we'll see how we can access subsections of our tables. Specific commands we'll review are:\n",
        "* `.columns` - list the column names\n",
        "* `.loc`, `.iloc`, `.at` and `.iat` - access parts of the table\n",
        "* `.notna` - check if elements are missing data\n",
        "* `.reset_index` - reset the index after downselected data\n",
        "* `.index` - get the index for selected data\n",
        "* `.sample` - get random samples from the data\n",
        "* `.query` - set up a logical query on the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajgIuXWJgMb_"
      },
      "source": [
        "# remind ourselves with our column names are\n",
        "df_spectra.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AvvBly4gQy-"
      },
      "source": [
        "# extract just one column\n",
        "df_spectra['SPEX_TYPE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EWQ5aoeBf05"
      },
      "source": [
        "# we can also access the column using the \"dot\" notation\n",
        "df_spectra.SOURCE_KEY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPIHBazcgxy4"
      },
      "source": [
        "# extract several rows\n",
        "df_spectra[['SOURCE_KEY','DATA_FILE','OBSERVER']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fYxvGurhBSn"
      },
      "source": [
        "# extact at one row\n",
        "df_spectra.loc[1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYLx8Ff1geob"
      },
      "source": [
        "# extract at a subset of rows\n",
        "df_spectra.loc[1490:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnMWKjk1hJ72"
      },
      "source": [
        "# extract a subset of columns and rows\n",
        "df_spectra.loc[10:20,['DATA_KEY','DATA_FILE','INSTRUMENT']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8Eo4kPOiAT2"
      },
      "source": [
        "# get one value - either of these methods works\n",
        "#df_spectra.iloc[10,10]\n",
        "#df_spectra.iat[10,10]\n",
        "dfsel = df_spectra['MEDIAN_SNR']\n",
        "dfsel.loc[10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL1bpvSFG7YH"
      },
      "source": [
        "df_spectra.loc[ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9cZKYrGijQg"
      },
      "source": [
        "Now let's select parts of our table based on a condition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snl7sIQviK6H"
      },
      "source": [
        "# select data observed on 20030522 (2003 May 22)\n",
        "df_spectra[df_spectra['OBSERVATION_DATE']==20030522]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09aWffW-ioP-"
      },
      "source": [
        "# select data for which the observer is known\n",
        "df_spectra[df_spectra['OBSERVER'].notna()==True]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReohS25pGeLo"
      },
      "source": [
        "# we can also find the index of a particular value\n",
        "ind = df_spectra[df_spectra['OBSERVATION_DATE']==20030522].index.values\n",
        "ind"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoHCDyLtjbNT"
      },
      "source": [
        "Notice that in both of these cases, the index of the table (the first column) is now out of order. We can fix this by saving the result to a new table and reseting the index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyR6RX4ojlxR"
      },
      "source": [
        "dfsel = df_spectra[df_spectra['OBSERVATION_DATE']==20030522]\n",
        "dfsel.reset_index(inplace=True,drop=False) # inplace=True means change the table, drop=True means get rid of the old index column\n",
        "dfsel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwK6IXwDkh_9"
      },
      "source": [
        "We can also select a random subset of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24ry4H2fklKr"
      },
      "source": [
        "# take just first 10 elements of DATA_KEY column and randomly draw one\n",
        "dfsel = df_spectra.loc[0:10,'DATA_FILE']\n",
        "dfsel.sample() # selects one object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvDtkQcWk_Pm"
      },
      "source": [
        "# now draw a few samples - try with and without replacement and see how it differs\n",
        "dfsel.sample(n=10,replace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOo564NzmBB5"
      },
      "source": [
        "A more complex way of accessing subsets of your data is using the `query` method, which allows you to set up a logical expression to select data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FX-whw_mLFD"
      },
      "source": [
        "# select data later than 2010 and S/N > 100\n",
        "df_spectra.query('(OBSERVATION_DATE >= 20100124 and MEDIAN_SNR > 100) and not SPEX_TYPE==\"L1.0\"')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD1k8JVmm2gg"
      },
      "source": [
        "# Exercise\n",
        "Using the source catalog, select a subset of the table with 30 < RA < 60 and DEC > 20, that are know to be VLM dwarfs (OBJECT_TYPE is VLM), and has an entry for SIMBAD_SPT. Make sure the final table has a reset index and contains only the columns NAME, DESIGNATION, OBJECT_TYPE, and SIMBAD_SPT. Confirm (based on the DESIGNATION) that the RA and DEC constraints worked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQf37Zh5nNKL"
      },
      "source": [
        "# Exercise Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBDgNoVpnQTe"
      },
      "source": [
        "# let's do these selections one at a time:\n",
        "dfsel = df_sources.query('RA > 30 and RA < 60 and DEC > 20')\n",
        "dfsel = dfsel[dfsel['OBJECT_TYPE']=='VLM']\n",
        "dfsel = dfsel[dfsel['SIMBAD_SPT'].notna()==True]\n",
        "dfsel = dfsel[['NAME','DESIGNATION','OBJECT_TYPE','SIMBAD_SPT']]\n",
        "dfsel.reset_index(inplace=True,drop=True)\n",
        "dfsel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IflaXK34ImT"
      },
      "source": [
        "# Part 3: Manipulating Tables\n",
        "\n",
        "In this section we'll see how we can manipulate our tables and combine columns together using numpy and other functions. Functions we'll look at include:\n",
        "\n",
        "* `.rename` - rename the column names\n",
        "* `.plot` - visualize the data\n",
        "* `.mean`, `.quantile`, and `.describe` - different quantitative summaries of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fFHwIyl4XSX"
      },
      "source": [
        "In addition to downselecting parts of our table, we can also rename columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfR6yjfK4fui"
      },
      "source": [
        "# make a small version of the df_photometry table and change a column name\n",
        "dfsel = df_photometry.loc[:20,['NAME','RA','DEC','J_2MASS','J_2MASS_E','H_2MASS','H_2MASS_E','KS_2MASS','KS_2MASS_E']]\n",
        "dfsel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpkImxno4xos"
      },
      "source": [
        "# change the column names for the photometry using .rename\n",
        "# setting inplace=True changes the table directly\n",
        "dfsel.rename(columns={'J_2MASS': 'J','H_2MASS': 'H','KS_2MASS': 'KS'},inplace=True)\n",
        "dfsel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWKOxeVq5WVu"
      },
      "source": [
        "Create new columns based on these data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRiSyNQX5aH8"
      },
      "source": [
        "# compute the colors J-H, H-KS, J-KS and their uncertainties\n",
        "dfsel['J-H'] = dfsel['J']-dfsel['H']\n",
        "dfsel['H-KS'] = dfsel['H']-dfsel['KS']\n",
        "dfsel['J-KS'] = dfsel['J']-dfsel['KS']\n",
        "dfsel['J-H unc'] = np.sqrt(dfsel['J_2MASS_E']**2+dfsel['H_2MASS_E']**2)\n",
        "dfsel['H-KS unc'] = np.sqrt(dfsel['H_2MASS_E']**2+dfsel['KS_2MASS_E']**2)\n",
        "dfsel['J-KS unc'] = np.sqrt(dfsel['J_2MASS_E']**2+dfsel['KS_2MASS_E']**2)\n",
        "dfsel\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RYdcDrh7DUq"
      },
      "source": [
        "Pandas can also do some basic statistical analysis of numerical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Au_OmLh7Kmy"
      },
      "source": [
        "# mean values\n",
        "dfsel.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MSvC_Do7p43"
      },
      "source": [
        "# quantiles\n",
        "dfsel.quantile([0.16,0.5,0.84])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B4wAC4371Hr"
      },
      "source": [
        "# a summary of the quantitative data\n",
        "dfsel.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMv77eGN52o3"
      },
      "source": [
        "Pandas also built-in matplotlib plotting tools to plot the data: see https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_user-5Fguide_visualization.html&d=DwIGAg&c=-35OiAkTchMrZOngvJPOeA&r=mrAiCY0TeV419Ak3rBjpNvgiyObFA_PAPlLMGcaX54A&m=SzQ4m99FotmuIWDN7LjY3UZc3sRvARoFNfDbkhA32x8&s=WKIkkM9rXHmTZUhQqRlLC-HZZSUdOGbC31BmPc64XMk&e=  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNJLXYD-58JG"
      },
      "source": [
        "# use pandas built in plotting tools to view the data - here's a scatter plot\n",
        "dfsel.plot(x='J-H',y='H-KS',xerr='J-H unc',yerr='H-KS unc',kind='scatter')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDdORlbNCtvr"
      },
      "source": [
        "# here's a histogram\n",
        "dfsel['J'].plot(kind='hist')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fha3FtOo8MMh"
      },
      "source": [
        "# box plot is a visual summary of the range of the data\n",
        "df1 = dfsel[['J-H','H-KS','J-KS']]\n",
        "df1.plot.box(vert=False) # vert=false makes this a horizontal plot, easier to read"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnoMjG9z8asl"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "Take the df_photometry table and create columns for the colors J_2MASS-KS_2MASS => J-K and I_SDSS-J_2MASS => I-J and their uncertainties. Remove all rows that have blank colors and make a scatter plot of these with uncertainties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZrSM6Ig90Ko"
      },
      "source": [
        "# Exercise Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xe3OPjp-Dbf"
      },
      "source": [
        "# let's first create the columns and then we'll clean it up\n",
        "dfsel = df_photometry.copy()\n",
        "dfsel['J-KS'] = dfsel['J_2MASS']-dfsel['KS_2MASS']\n",
        "dfsel['I-J'] = dfsel['I_SDSS']-dfsel['J_2MASS']\n",
        "dfsel['I-J unc'] = np.sqrt(dfsel['J_2MASS_E']**2+dfsel['I_SDSS_E']**2)\n",
        "dfsel['J-KS unc'] = np.sqrt(dfsel['J_2MASS_E']**2+dfsel['KS_2MASS_E']**2)\n",
        "dfsel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfpwQHo7_RYz"
      },
      "source": [
        "# reject the columns that have missing data\n",
        "dfsel = dfsel[dfsel['J-KS'].notna()==True]\n",
        "dfsel = dfsel[dfsel['I-J'].notna()==True]\n",
        "dfsel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0K9SR_w_b62"
      },
      "source": [
        "# now plot it\n",
        "dfsel.plot(x='I-J',y='J-KS',xerr='I-J unc',yerr='J-KS unc',kind='scatter')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TemExCfMeyH4"
      },
      "source": [
        "# Part 4: Combining tables\n",
        "\n",
        "The most powerful feature of pandas is the ability to merge and combine tables, allowing us to compare different datasets to each other. There are multiple ways of combining tables (stacking, union, intersection) that give different results.\n",
        "\n",
        "Commands we'll use are:\n",
        "* `pd.concat` - concatenation of tables\n",
        "* `.append` - append one table onto another\n",
        "* `pd.merge` - merge tables on a common column\n",
        "\n",
        "A helpful reference is https://urldefense.proofpoint.com/v2/url?u=https-3A__pandas.pydata.org_pandas-2Ddocs_stable_user-5Fguide_merging.html&d=DwIGAg&c=-35OiAkTchMrZOngvJPOeA&r=mrAiCY0TeV419Ak3rBjpNvgiyObFA_PAPlLMGcaX54A&m=SzQ4m99FotmuIWDN7LjY3UZc3sRvARoFNfDbkhA32x8&s=BRLHHeoSgizD-OkO1bNG4qIhtAgccxa-x28wXXDv3ss&e=  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MttgB70eftU5"
      },
      "source": [
        "# print out the columns of the df_spectra and df_sources tables - note that there is a column in common!\n",
        "print(df_spectra.columns)\n",
        "print(df_sources.columns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_orX0a2p2O_"
      },
      "source": [
        "# first try just a simple concat - notice you'll end up with a table that is twice as long\n",
        "# look in particular at the pattern of NaNs (missing data) in the merged table\n",
        "result = pd.concat([df_spectra,df_sources])\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e5nG8GOrAla"
      },
      "source": [
        "# now add the join='inner' option - how is this different?\n",
        "result = pd.concat([df_spectra,df_sources],join='inner')\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujke81gereVW"
      },
      "source": [
        "# now add the join='inner' option - how is this different?\n",
        "result = pd.concat([df_spectra,df_sources],axis=1)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPtUbmfnrpej"
      },
      "source": [
        "# you can also use the append function to append one Dataframe onto another\n",
        "result = df_spectra.append(df_sources)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyu6qnx1slal"
      },
      "source": [
        "None of these operations actually merged the data - it just returned a stack of both dataframes or the columns that were in common; `merge` is the method that allows us to find agreement between two datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG5rENEZsOFD"
      },
      "source": [
        "# try a simple merge\n",
        "result = pd.merge(df_spectra,df_sources,on='SOURCE_KEY')\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36SiH2k5s_qt"
      },
      "source": [
        "# we can vary how it merges by using the how parameter = 'left', 'right', 'outer' or 'inner'\n",
        "# explore these options!\n",
        "result = pd.merge(df_spectra,df_sources,on='SOURCE_KEY',how='outer')\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBDOMoJawa5K"
      },
      "source": [
        "Note that one column shows up twice in the list above - NOTE_x and NOTE_y - since both tables have this. You can control how these are labeled by using the suffixes parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsUxlxz9wkbn"
      },
      "source": [
        "result = pd.merge(df_spectra,df_sources,on='SOURCE_KEY',suffixes=('_old','_new'))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5oB5U1ivhMY"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "Determine which sources are present in the df_sources, df_spectra and df_photometry tables, and return the DESIGNATION, DATA_FILE, H_2MASS, and MEDIAN_SNR information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP7-aoLfvysU"
      },
      "source": [
        "# Exercise Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LatAvH0uGNm"
      },
      "source": [
        "# use the merge command twice, on SOURCE_KEY\n",
        "df1 = pd.merge(df_sources,df_spectra,on='SOURCE_KEY')\n",
        "df2 = pd.merge(df1,df_photometry,on='SOURCE_KEY',suffixes=('_old',''))\n",
        "df2 = df2[['DESIGNATION','DATA_FILE','H_2MASS','MEDIAN_SNR']]\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbXkF5N6wFRo"
      },
      "source": [
        "df_photometry.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uij8mBCxNlT"
      },
      "source": [
        "# Part 5: Saving tables and other file formats\n",
        "\n",
        "In this part we'll see how we can save our files into different formats. \n",
        "\n",
        "Commands we'll look at include\n",
        "* `.to_csv` - save to csv (comma-separated variables) file\n",
        "* `.to_excel` - save to excel\n",
        "* `.to_latex` - save to a latex table\n",
        "* `.to_dict` - save to a dictionary variable\n",
        "\n",
        "If you are using Google colab, you can access the files you create from the folder icon on the upper left of the screen; the files you create will be under /content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLlOC80IxpHs"
      },
      "source": [
        "# let's first create a small table to save\n",
        "dfsel = pd.merge(df_sources,df_spectra,on='SOURCE_KEY')\n",
        "dfsel = dfsel[dfsel['SIMBAD_SPT'].notna()==True]\n",
        "dfsel = dfsel[dfsel['MEDIAN_SNR'] > 100]\n",
        "dfsel.reset_index(inplace=True,drop=True)\n",
        "dfsel = dfsel[['DESIGNATION','DATA_FILE','J_2MASS','SIMBAD_SPT']]\n",
        "dfsel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duskknfsx2vB"
      },
      "source": [
        "# export this as a csv file\n",
        "# not the index=False assures that this extra column isn't left in\n",
        "dfsel.to_csv('mytable.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqd86oPhycL-"
      },
      "source": [
        "# export this as a excel file\n",
        "# not the index=False assures that this extra column isn't left in\n",
        "dfsel.to_excel('mytable.xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8l1lZrdyvOS"
      },
      "source": [
        "# export this as a latex table file\n",
        "# not the index=False assures that this extra column isn't left in\n",
        "dfsel.to_latex('mytable.tex',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnzbsWMRy7IQ"
      },
      "source": [
        "# save the first 10 rows as a dictionary\n",
        "dfsel.loc[:9].to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrA986zp0EMR"
      },
      "source": [
        "# make it so each key points to the list of values (a better format)\n",
        "dfsel.loc[0:9].to_dict(orient='list')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvnZx8s9zUa3"
      },
      "source": [
        "# organize separately so that each row is an element\n",
        "dfsel.loc[0:9].to_dict(orient='index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwCxVDiZzza4"
      },
      "source": [
        "# lets try the opposite - turn a dictionary into a pandas table\n",
        "d = {'NAME': ['Adam','Sandy','Eibar','Roman','Carlos'],'SCORE': [1,3,5,6,1]}\n",
        "df = pd.DataFrame(d)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAt8cBts0p31"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "Create a table from the df_sources and df_spectra catalogs, selecting all sources observed on 20030522 that have OBJECT_TYPE = VLM and SIMBAD_SPT present. Save this table off as a latex table with column names DESIGNATION => Source, DATA_FILE => Filename, SIMBAD_SPT => SpT, J_2MASS => 2MASS J, and MEDIAN_SNR => S/N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or5Yj0iL1jwy"
      },
      "source": [
        "# Exercise Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lfdTxAC0dsv"
      },
      "source": [
        "# first merge the spreadsheets and make selection cuts\n",
        "dfsel = pd.merge(df_sources,df_spectra,on='SOURCE_KEY',how='inner')\n",
        "dfsel = dfsel[dfsel['OBSERVATION_DATE']==20030522]\n",
        "dfsel = dfsel[dfsel['OBJECT_TYPE']=='VLM']\n",
        "dfsel = dfsel[dfsel['SIMBAD_SPT'].notna()==True]\n",
        "dfsel\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCUs1WgF1-0h"
      },
      "source": [
        "# now select and rename columns\n",
        "dftable = dfsel[['DESIGNATION','DATA_FILE','SIMBAD_SPT','J_2MASS','MEDIAN_SNR']]\n",
        "dftable.rename(columns={'DESIGNATION': 'Source','DATA_FILE': 'Filename','SIMBAD_SPT': 'SpT', 'J_2MASS': 'J','MEDIAN_SNR': 'S/N'},inplace=True)\n",
        "dftable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73gg-o0C2ny_"
      },
      "source": [
        "# now save to latex file\n",
        "dftable.to_latex('exercise_part4_table.tex',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}